<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>JING</title>
        <link>https://JING.github.io/</link>
        <description>Recent content on JING</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>JING</copyright>
        <lastBuildDate>Mon, 04 Nov 2024 13:31:44 +0800</lastBuildDate><atom:link href="https://JING.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>通用信息抽取3 | InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction</title>
        <link>https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%963-instructuie-multi-task-instruction-tuning-for-unified-information-extraction/</link>
        <pubDate>Mon, 04 Nov 2024 13:31:44 +0800</pubDate>
        
        <guid>https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%963-instructuie-multi-task-instruction-tuning-for-unified-information-extraction/</guid>
        <description>&lt;img src="https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%963-instructuie-multi-task-instruction-tuning-for-unified-information-extraction/framework.jpg" alt="Featured image of post 通用信息抽取3 | InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction" /&gt;&lt;img src=&#34;authors.jpg&#34; style=&#34;zoom:70%&#34; /&gt;
&lt;p&gt;论文：https://arxiv.org/abs/2304.08085&lt;br&gt;
代码：https://github.com/BeyonderXX/InstructUIE&lt;/p&gt;
&lt;img src=&#34;introduction.jpg&#34; style=&#34;zoom:60%&#34; /&gt;
&lt;p&gt;之前的笔记中我们介绍了UIE(通用信息抽取1)和USM(通用信息抽取2)。我们先回顾一下这两篇工作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;UIE&lt;br&gt;
UIE通过设计的结构提取语言SEL对异构IE结构进行统一建模，使用结构模式指令器SSI为不同IE任务生成目标结构，通过在多个数据集上预训练模型捕获通用IE能力。&lt;br&gt;
UIE将IE任务统一为seq2seq生成任务，输入为文本形式，输出为对应的结构化信息。&lt;br&gt;
局限性：由于不同任务的输出模式可能不同，UIE需要针对不同的下游任务进行单独的微调，以生成特定格式的输出。&lt;/li&gt;
&lt;li&gt;USM&lt;br&gt;
USM将IE任务解耦为结构化和概念化两个基本任务。通过TTL操作结构化信息，获取基本信息单元。通过LTL、TLL操作概念化信息，在label和基本信息单元间建立链接。&lt;br&gt;
USM基于语义匹配机制，通过比对文本span与语义标签的相似性来完成IE任务。&lt;br&gt;
局限性：将IE转化为语义匹配任务，难以与生成式语言模型集成；需要对每个单词进行语义匹配，导致训练和推理时间显著增加。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;LLM通过多任务训练和统一编码展现出强大的泛化能力，而有研究表明，LLM在IE任务上仍有显著的性能差距。&lt;/p&gt;
&lt;p&gt;那么，是否有办法激发LLM的潜在知识来完成IE任务？&lt;/p&gt;
&lt;h2 id=&#34;instructuie&#34;&gt;InstructUIE
&lt;/h2&gt;&lt;h3 id=&#34;task-schema&#34;&gt;Task Schema
&lt;/h3&gt;&lt;p&gt;为了更好地转移和利用在预训练语言模型中学习到的知识，将IE任务重新表述为seq2seq形式，并微调LLM。如图所示，每个任务实例都用四个属性格式化：&lt;br&gt;
&lt;img src=&#34;example1.jpg&#34; style=&#34;zoom:50%&#34; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;任务指令(Task Instruction)：提供详细的指导，说明如何从输入文本中提取相关信息，并生成所需的输出结构。具体内容包括要提取的信息类型、输出结构的格式以及提取过程中需要遵循的额外约束或规则。&lt;/li&gt;
&lt;li&gt;选项(Options)：定义任务的输出标签约束，表示模型可以为给定输入生成的可能输出集。例如，在命名实体识别(NER)中，选项可能包括&amp;quot;person&amp;quot;、&amp;ldquo;organization&amp;rdquo;、&amp;ldquo;location&amp;quot;等实体标签；在关系提取(RE)中，选项可能代表可以提取的关系类型，如&amp;quot;works for&amp;rdquo;、&amp;ldquo;born in&amp;quot;等；在事件提取(EE)中，选项可能对应不同事件类型的标签，如&amp;quot;beginning&amp;rdquo;、&amp;ldquo;end&amp;quot;等。&lt;/li&gt;
&lt;li&gt;文本(Text)：任务实例的输入句子，与任务指令和选项一起输入预训练的语言模型，使模型能够为给定任务生成所需的输出序列。&lt;/li&gt;
&lt;li&gt;输出(Output)：将样本的原始标签转换为句子格式。对于NER，输出格式为&amp;quot;entity tag: entity span&amp;rdquo;；对于RE，输出格式为&amp;quot;relationship: head entity, tail entity&amp;quot;； 对于EE，输出格式为&amp;quot;event tag: trigger word, argument tag: argument span&amp;quot;； 如果输入中没有与提供选项匹配的结构信息，则输出&amp;quot;None&amp;quot;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;auxiliary-tasks&#34;&gt;Auxiliary Tasks
&lt;/h3&gt;&lt;p&gt;辅助任务，与主任务一起训练。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NER：引入了span extraction task和entity typing task。span extraction task旨在从输入句子中提取实体span，而entity typing task旨在识别实体的类型。&lt;/li&gt;
&lt;li&gt;RE：引入了entity pair extraction task和relation classification task。entity pair extraction task旨在提取关系中涉及的实体对，而relation classification task旨在对实体对之间的关系类型进行分类。&lt;/li&gt;
&lt;li&gt;EE：引入了trigger extraction task和argument extraction task。trigger extraction task旨在提取触发事件的触发词，而argument extraction task旨在提取相关的参数。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ie-instructions&#34;&gt;IE INSTRUCTIONS
&lt;/h2&gt;&lt;p&gt;IE INSTRUCTIONS收集了32个公开可用的数据集，涵盖三种类型的IE任务：NER、RE和EE。除了新闻和维基数据等通用领域的来源之外，还包括来自科学、医疗保健、社交媒体和交通等各个领域的语料库，以确保数据集的多样性。&lt;br&gt;
数据处理步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;统一不同数据集中语义相同但名称不同的标签的名称。&lt;/li&gt;
&lt;li&gt;将带有下划线、缩写或特殊格式的标签转换为自然语言格式。例如，将标签&amp;quot;people person place of birth&amp;quot;重命名为&amp;quot;place of birth&amp;quot;。&lt;/li&gt;
&lt;li&gt;将所有数据集转换为文本到文本格式，确保所有任务中输入输出对的一致表示。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;数据集构成如图所示：&lt;br&gt;
&lt;img src=&#34;dataset.jpg&#34; style=&#34;zoom:50%&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments
&lt;/h2&gt;&lt;p&gt;backbone：FlanT5-11B&lt;/p&gt;
&lt;h3 id=&#34;supervised-experiments&#34;&gt;Supervised Experiments
&lt;/h3&gt;&lt;p&gt;Supervised学习设置：在训练期间为所有任务提供指令，模型在每个任务的标注数据上进行微调，使其能够学习特定任务的特征。为了平衡数据集，作者采用了抽样策略。即为每个数据集采样10,000个示例，少于10,000个样本的数据集使用所有示例。&lt;br&gt;
&lt;img src=&#34;supervised_experiment1.jpg&#34; style=&#34;zoom:65%&#34; /&gt;&lt;br&gt;
&lt;img src=&#34;supervised_experiment2.jpg&#34; style=&#34;zoom:53%&#34; /&gt;&lt;br&gt;
&lt;img src=&#34;supervised_experiment3.jpg&#34; style=&#34;zoom:57%&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;zero-shot-experiments&#34;&gt;Zero-shot Experiments
&lt;/h3&gt;&lt;p&gt;Zero-shot学习设置：在训练期间仅为部分任务提供指令，模型在未见过的任务上进行评估，无需额外的微调。作者在18个NER数据集和6个RE数据集上训练了模型，并在7个NER数据集和2个RE数据集上进行测试(训练阶段删除了zero-shot实验需要测试的数据集)。&lt;br&gt;
&lt;img src=&#34;zero_shot_experiment1.jpg&#34; style=&#34;zoom:60%&#34; /&gt;&lt;br&gt;
&lt;img src=&#34;zero_shot_experiment2.jpg&#34; style=&#34;zoom:60%&#34; /&gt;&lt;br&gt;
&lt;img src=&#34;zero_shot_experiment3.jpg&#34; style=&#34;zoom:60%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ps：详细的实验结果可以查看原文。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;提出了UIE的一个End-to-End框架——InstructUIE，它利用自然语言指令来指导IE任务。&lt;/li&gt;
&lt;li&gt;引入新的基准数据集IE INSTRUCTIONS。该基准由32个不同的信息提取数据集组成，这些数据集已统一为文本到文本格式，允许对各种IE任务进行一致和标准化的评估。&lt;/li&gt;
&lt;li&gt;实验结果表明，InstructUIE在监督和zero-shot下实现了SOTA，使用单个多任务模型解决了多个任务。&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>通用信息抽取2 | Universal Information Extraction as Unified Semantic Matching</title>
        <link>https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%962-universal-information-extraction-as-unified-semantic-matching/</link>
        <pubDate>Sun, 03 Nov 2024 09:27:34 +0800</pubDate>
        
        <guid>https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%962-universal-information-extraction-as-unified-semantic-matching/</guid>
        <description>&lt;img src="https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%962-universal-information-extraction-as-unified-semantic-matching/cover.jpg" alt="Featured image of post 通用信息抽取2 | Universal Information Extraction as Unified Semantic Matching" /&gt;&lt;img src=&#34;authors.jpg&#34; style=&#34;zoom:43%&#34; /&gt;
&lt;p&gt;论文：https://arxiv.org/abs/2301.03282&lt;br&gt;
Accepted by AAAI2023&lt;/p&gt;
&lt;p&gt;上一篇我们介绍了UIE，它采用了文本-结构、seq2seq的生成方法。这一方法具有&amp;quot;黑盒&amp;quot;特性，信息片段(如实体、关系、关键词等)和模式(如输出结构)之间的关联是隐式的，这可能导致以下问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;由于模型在生成过程中不显式地展示哪些信息片段与模式相关联，因此难以判断模型学到了哪些知识。无法判断它是否真正理解了实体关系，还是仅仅是在模拟训练数据的表面模式。&lt;/li&gt;
&lt;li&gt;由于信息片段和生成模式的关联是隐式的，在迁移到新的任务或模式时，模型是否能够正确应用已有知识变得难以预测。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note：输入的信息被编码器编码成一组上下文向量，这些向量包含了输入的所有信息。但这些向量本身是高度抽象的，并没有显式地表示出输入中的特定信息片段(如重要的实体或关系)。而输出的每一步依赖于隐含的上下文向量和之前的输出，这种生成方式也没有显式地表现模型是如何将某些输入信息片段映射到具体的输出部分的。由于这些关联是隐含的，很难解释模型在生成过程中是如何决策的。例如，模型可能在输出中提到了某个关键实体，但难以追踪它是根据哪个输入信息片段得出的。&lt;/p&gt;
&lt;p&gt;因此，作者认为，为了确保有效、稳健和可解释的迁移能力，显式建模和学习可迁移的知识是必要的。&lt;/p&gt;
&lt;h2 id=&#34;unified-semantic-matching-via-directed-token-linking&#34;&gt;Unified Semantic Matching via Directed Token Linking
&lt;/h2&gt;&lt;h3 id=&#34;schema-text-joint-embedding&#34;&gt;Schema-Text Joint Embedding
&lt;/h3&gt;&lt;p&gt;为了让模型理解标签模式(schema)和文本之间的关联(同时捕捉标签和文本之间的语义关系)，USM对提取模式(schema)和文本token进行共同编码，从而生成它们的联合上下文嵌入：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提取模式词序列化：USM将提取模式(schema)表示为一个词序列。例如，如果提取模式是&amp;quot;person&amp;quot;和&amp;quot;location&amp;quot;这样的标签，USM会将这些标签转换为词序列形式，即{$l_1,l_2,&amp;hellip;,l_{|l|}$}。(类似文本token)&lt;/li&gt;
&lt;li&gt;拼接schema和文本：USM将词序列化后的schema sequence与文本token{$t_1,t_2,&amp;hellip;,t_{|t|}$}进行拼接，一起作为模型的输入。&lt;/li&gt;
&lt;li&gt;Transformer编码器：拼接后的词序列和文本通过一个Transformer编码器进行处理，计算出联合的上下文嵌入H，表示为$[h_1,h_2,&amp;hellip;,h_{|l|+|t|]$。&lt;/li&gt;
&lt;li&gt;Mask矩阵：M是一个Mask矩阵，用来决定哪些标签或文本token可以互相&amp;quot;看到&amp;quot;(self-attention)，从而捕捉它们之间的交互关系。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终，联合标签-文本嵌入可以表示为：
&lt;/p&gt;
$$
H = Encoder(l_1,l_2,...,l_{|l|},t_1,t_2,...,t_{|t|},M)
$$&lt;h3 id=&#34;token-linking-operations&#34;&gt;Token Linking Operations
&lt;/h3&gt;&lt;p&gt;要实现UIE，还是要对不同IE任务进行统一建模。&lt;br&gt;
类似UIE的定位(Spotting)和关联(Associating)，作者将IE任务解耦为两个操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;结构化(Structuring)：从文本中抽取出与标签无关的基本子结构。例如，实体抽取&amp;quot;Monet&amp;quot;；事件触发词&amp;quot;born in&amp;quot;；关系实体对(&amp;ldquo;Monet&amp;rdquo;，&amp;ldquo;Paris&amp;rdquo;)；事件论元(&amp;ldquo;born in&amp;rdquo;，&amp;ldquo;Paris&amp;rdquo;)。&lt;/li&gt;
&lt;li&gt;概念化(Conceptualizing)：在概念化阶段将这些具体子结构与语义标签相连接。例如：&amp;ldquo;Monet&amp;quot;可以标记为&amp;quot;person&amp;rdquo;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中，结构化通过Token-Token Linking (TTL)操作实现，概念化通过Label-Token Linking (LTL)和Token-Label Linking (TLL)操作实现。&lt;/p&gt;
&lt;h4 id=&#34;token-token-linking-for-structuring-ttl&#34;&gt;Token-Token Linking for Structuring (TTL)
&lt;/h4&gt;&lt;p&gt;前面我们提到，结构化的目标是要提取出文本中的基本信息单元(如实体、关系、触发词等)。这些基本信息单元是一组连续的token序列，我们需要知道单个信息单元是从哪里开始、又从哪里结束。&lt;br&gt;
而部分IE任务所需的结构可能包括不止一个信息单元，例如{&amp;ldquo;Monet&amp;rdquo;, birth place, &amp;ldquo;Paris&amp;rdquo;}就是一个三元组的形式，此时，我们则需要找到Subject-Object对。&lt;br&gt;
作者设计了TTL操作，从两个方面对输入文本中所有有效的子结构进行构造：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Utterance(文本)：指输入文本中的连续token序列，例如实体(如&amp;quot;Monet&amp;quot;)或事件触发词(如&amp;quot;born in&amp;quot;)。
&lt;img src=&#34;TTL_example1.jpg&#34; style=&#34;zoom:40%&#34; /&gt;&lt;br&gt;
如图所示，其实就是将头和尾链接(H2T)。例如，为了提取span&amp;quot;Monet&amp;quot;和&amp;quot;born in&amp;quot;作为有效的子结构，USM利用H2T将&amp;quot;Monet&amp;quot;链接到自身来提取&amp;quot;Monet&amp;quot;，并将&amp;quot;born&amp;quot;链接到&amp;quot;in&amp;quot;以提取&amp;quot;born in&amp;quot;。&lt;/li&gt;
&lt;li&gt;Association Pair(文本对)：从文本中提取的基本关联对单元，例如关系的Subject-Object对(如&amp;quot;Monet&amp;quot;和&amp;quot;Paris&amp;quot;)或事件触发词-参数对(如&amp;quot;born in&amp;quot;和&amp;quot;Paris&amp;quot;)。
&lt;img src=&#34;TTL_example2.jpg&#34; style=&#34;zoom:40%&#34; /&gt;&lt;br&gt;
如图所示，链接关联对是将头与头链接(H2H)、尾与尾链接(T2T)。例如，要提取Subject-Object对&amp;quot;Monet&amp;quot;和&amp;quot;Paris&amp;quot;，USM通过H2H将&amp;quot;Monet&amp;quot;和&amp;quot;Paris&amp;quot;链接起来，同时也通过T2T链接这两个token。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;USM通过计算每对有效token对$&amp;lt;t_i,t_j&amp;gt;$的链接分数$s_{TTL}(t_i,t_j)$(表示token之间的相似度或相关性，高分数意味着这两个token在上下文中有较强的关联性，适合进行链接)来实现上述的H2T、H2H和T2T链接操作。链接分数的计算公式如下：&lt;br&gt;
&lt;/p&gt;
$$
s_{TTL}(t_i,t_j) = FFNN_{TTL}^l(h_t^i)^TR_{j-i}FFNN_{TTL}^r(h_t^j)
$$&lt;p&gt;
其中，FFNN为前馈神经网络层，用于处理token的嵌入信息。$R_{j-i}$是一个旋转位置嵌入(用于编码token之间的相对位置关系)。通过这种方式，模型可以捕捉到token之间的相对位置关系。&lt;/p&gt;
&lt;h4 id=&#34;label-token-linking-for-utterance-conceptualizing-ltl&#34;&gt;Label-Token Linking for Utterance Conceptualizing (LTL)
&lt;/h4&gt;&lt;p&gt;结构化是从Utterance和Association Pair两个方面来进行处理的，概念化也是如此。首先考虑Utterance的概念化，包括两种类型：&lt;br&gt;
&lt;img src=&#34;LTL_example.jpg&#34; style=&#34;zoom:40%&#34; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Type of Mention：将标签类型直接分配给span。例如，将实体&amp;quot;Monet&amp;quot;标记为类型&amp;quot;person&amp;quot;，&amp;ldquo;France&amp;quot;标记为类型&amp;quot;country&amp;rdquo;。&lt;/li&gt;
&lt;li&gt;Predicate of Object：将关系标签分配给Association Pair中的Object。例如，&amp;ldquo;Paris&amp;quot;的关系类型&amp;quot;birth place&amp;rdquo;，事件参数类型&amp;quot;capital&amp;quot;。
用label-to-head(L2H)和label-to-tail(L2T)链接操作来为每个子结构分配标签(其实也是头对头、尾对尾，只是不是将信息单元进行链接了，而是将标签与信息单元进行链接)。链接分数的计算公式如下：
$$
s_{LTL}(l_i,t_j) = FFNN_{LTL}^{label}(h_i^l)^TR_{j-i}FFNN_{LTL}^{Text}(h_j^t)
$$&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;token-label-linking-for-pairing-conceptualizing-tll&#34;&gt;Token-Label Linking for Pairing Conceptualizing (TLL)
&lt;/h4&gt;&lt;p&gt;考虑Association Pair的概念化。在LTL中，已经链接了label到Association Pair中的Object，还需要链接label和Association Pair中的Subject。这样就可以根据多条路径确定一个三元组：&lt;br&gt;
TTL：(Subject, Object)&lt;br&gt;
LTL：(Association, Object)&lt;br&gt;
TLL：(Subject, Association)&lt;br&gt;
&lt;img src=&#34;TLL_example.jpg&#34; style=&#34;zoom:40%&#34; /&gt;&lt;br&gt;
链接方式与LTL类似，还是头对头、尾对位的链接，但链接方向不同，链接通过head-to-label(H2L)和tail-to-label(T2L)实现。链接分数的计算公式如下：
&lt;/p&gt;
$$
s_{TTL}(t_i,l_j) = FFNN_{TLL}^{text}(h_i^l)^TR_{j-i}FFNN_{TLL}^{label}(h_j^t)
$$&lt;h3 id=&#34;schema-text-joint-embedding-1&#34;&gt;Schema-Text Joint Embedding
&lt;/h3&gt;&lt;p&gt;通过schema-constraint解码，如图所示：&lt;br&gt;
&lt;img src=&#34;framework.jpg&#34; style=&#34;zoom:60%&#34; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过TTL操作提取的内容：例如，{&amp;ldquo;Monet&amp;rdquo;, &amp;ldquo;Paris&amp;rdquo;, &amp;ldquo;France&amp;rdquo;, (&amp;ldquo;Monet&amp;rdquo;, &amp;ldquo;Pairs&amp;rdquo;), (&amp;ldquo;France&amp;rdquo;, &amp;ldquo;Pairs&amp;rdquo;)}，抽取得到&amp;quot;Monet&amp;quot;和&amp;quot;Paris&amp;quot;，以及Subject-Object对(&amp;ldquo;Monet&amp;rdquo;, &amp;ldquo;Paris&amp;rdquo;)和(&amp;ldquo;France&amp;rdquo;, &amp;ldquo;Paris&amp;rdquo;)。&lt;/li&gt;
&lt;li&gt;通过LTL操作提取的内容：例如，{(person, &amp;ldquo;Monet&amp;rdquo;), (country, &amp;ldquo;France&amp;rdquo;), (birth place, &amp;ldquo;Paris&amp;rdquo;), (capital, &amp;ldquo;Paris&amp;rdquo;)}，每个label(如person、country)都与相应的Object(如&amp;quot;Monet&amp;quot;、&amp;ldquo;France&amp;rdquo;)相关联。&lt;/li&gt;
&lt;li&gt;通过TLL操作提取的内容：例如，(&amp;ldquo;Monet&amp;rdquo;, birth place), (&amp;ldquo;France&amp;rdquo;, capital)，将Subject与其相应的关系label(如birth place、capital)联系起来。&lt;/li&gt;
&lt;li&gt;基于获得的label-token间的链接(例如&amp;quot;Monet&amp;quot;与&amp;quot;birth place&amp;quot;以及&amp;quot;France&amp;quot;与&amp;quot;capital&amp;quot;)，USM能够一致地生成完整的结构，例如：(&amp;ldquo;Monet&amp;rdquo;, birth place, &amp;ldquo;Paris&amp;rdquo;)和(&amp;ldquo;France&amp;rdquo;, capital, &amp;ldquo;Paris&amp;rdquo;)。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些解码步骤之间是独立的，这意味着提取操作是完全非自回归的(non-autoregressive)，这使得解码过程可以并行进行。&lt;/p&gt;
&lt;h2 id=&#34;learning-from-heterogeneous-supervision&#34;&gt;Learning from Heterogeneous Supervision
&lt;/h2&gt;&lt;p&gt;USM使用了标签的词序列化表示(verbalized label representation)和统一的token链接机制，不论资源的来源或类型如何，USM将它们统一表示为&amp;lt;text, token pairs&amp;gt;进行预训练。&lt;/p&gt;
&lt;h3 id=&#34;pre-training&#34;&gt;Pre-training
&lt;/h3&gt;&lt;p&gt;异构监督资源(来源不同、类型多样的训练数据)包括任务注释信号(例如，IE数据集)、远程信号(例如，远程监督数据集)和间接信号(例如，QA数据集)三种不同类型：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$D_{task}$(任务标注数据集)&lt;br&gt;
其中每个实例都有一个用于信息提取的标准注释。本文使用在信息提取领域广泛使用的Ontonotes作为标准注释，它包含18种实体类型。
任务标注数据集用于帮助模型学习任务特定的结构化和概念化能力。即通过这些标注数据，模型可以学习如何准确地从文本中提取特定类型的实体和关系。&lt;/li&gt;
&lt;li&gt;$D_{distant}$(远程监督数据集)&lt;br&gt;
远程监督数据集是通过将文本与知识库对齐来生成的标注数据。本文使用NYT和Rebel作为远程监督数据集，这些数据集分别是通过将文本与Freebase和Wikidata对齐而获得。由于Rebel数据集的标签模式过长，不适合直接与输入文本拼接并输入到预训练的Transformer编码器中。因此，本文采样了负标签(与输入文本的实际内容没有对应关系的标签)模式构建meta schema，简化预训练时的标签模式。
远程监督数据为模型提供大规模的训练数据，帮助模型学习广泛的结构和概念化能力。&lt;/li&gt;
&lt;li&gt;$D_{indirect}$(间接监督数据集)&lt;br&gt;
间接监督数据集来自与信息抽取相关的其他NLP任务，主要是阅读理解数据集。本文使用MRQA中的阅读理解数据集，如HotpotQA、Natural Questions、NewsQA、SQuAD、TriviaQA等。
间接监督数据集通过多样化的问题表达，提供了比$D_{task}$和$D_{distant}$更多样化的标签语义信息，有助于模型学习更丰富的概念化能力(增强泛化能力)。对于每个(question，context，answer)实例，问题作为label schema，context作为输入文本，answer作为mention。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;learning-function&#34;&gt;Learning function
&lt;/h3&gt;&lt;p&gt;在USM学习过程中，面临的主要挑战是链接对的稀疏性(链接对仅占所有有效标记对候选项的不到1%)，为了应对这种极端的链接实例稀疏性，USM使用了优化的类别不平衡损失。
&lt;/p&gt;
$$
L = \sum_{m \in \mathcal{M}} log \left(1+\sum_{(i, j) \in m^{+}} e^{-s_{m}(i, j)}\right) +\log \left(1+\sum_{(i, j) \in m^{-}} e^{s_{m}(i, j)}\right)
$$&lt;p&gt;
损失函数由两部分组成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;针对已链接对$m^+$的损失，利用链接评分$s_m (i,j)$来计算概率，增加与正样本的联系。&lt;/li&gt;
&lt;li&gt;针对未链接对$m^-$的损失，同样基于链接评分，但通过对未链接的对进行惩罚，降低其影响。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments
&lt;/h2&gt;&lt;p&gt;对比USM和其他SOTA模型在4个任务的13个数据集上的性能。AVE-unify表示非重叠数据集的平均性能，AVE-total表示所有数据集的平均性能。USM实现了SOTA，在不使用预训练模型的情况下，用RoBERTa初始化的USM框架也表现出了较好的效果。&lt;br&gt;
&lt;img src=&#34;experiment1.jpg&#34; style=&#34;zoom:45%&#34; /&gt;&lt;br&gt;
在不同领域的9个数据集上进行zero-shot实验。即使从实体类型有限的$D_{task}$中学习，USM在电影、文学和音乐领域也表现出良好的迁移性能。$D_{distant}$和$D_{indirect}$在预训练过程中有重要作用。&lt;br&gt;
&lt;img src=&#34;experiment2.jpg&#34; style=&#34;zoom:45%&#34; /&gt;&lt;br&gt;
USM(356M)以较小的模型大小优于强zero-shot基线GPT-3(175B)和DEEPSTRUCTURE(10B)。&lt;br&gt;
&lt;img src=&#34;experiment3.jpg&#34; style=&#34;zoom:45%&#34; /&gt;&lt;br&gt;
(详细的实验结果和分析可以查看原文)&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;提出了一个统一的语义匹配框架——USM。&lt;/li&gt;
&lt;li&gt;UIE方法未能显式地展示信息片段与模式的关联、知识迁移效果难以预测 ——&amp;gt; USM通过结构化和概念化显式地建立了信息片段与标签之间的关联&lt;br&gt;
(例如，当迁移到新任务时，USM不需要重新学习基本的信息抽取能力，而是只需要在新领域中重新定义或调整概念化标签。这种显式关联使得知识的迁移更加系统化，减少了模型在新任务中的不确定性)&lt;/li&gt;
&lt;li&gt;USM在监督实验下达到了最先进的性能，在zero/few shot设置下表现出很强的泛化能力。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References
&lt;/h2&gt;&lt;p&gt;[1] &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_27590277/article/details/128699655?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522A7AAA045-C8D2-470D-8CB4-6FB0D7220C7D%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=A7AAA045-C8D2-470D-8CB4-6FB0D7220C7D&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-2-128699655-null-null.142%5ev100%5epc_search_result_base1&amp;amp;utm_term=Universal%20Information%20Extraction%20as%20Unified%20Semantic%20Matching&amp;amp;spm=1018.2226.3001.4187&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/qq_27590277/article/details/128699655?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522A7AAA045-C8D2-470D-8CB4-6FB0D7220C7D%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=A7AAA045-C8D2-470D-8CB4-6FB0D7220C7D&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-2-128699655-null-null.142^v100^pc_search_result_base1&amp;utm_term=Universal%20Information%20Extraction%20as%20Unified%20Semantic%20Matching&amp;spm=1018.2226.3001.4187&lt;/a&gt;&lt;br&gt;
[2] &lt;a class=&#34;link&#34; href=&#34;https://adaning.github.io/posts/11838.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://adaning.github.io/posts/11838.html&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>扩散模型1 | Deep Unsupervised Learning using Nonequilibrium Thermodynamics</title>
        <link>https://JING.github.io/p/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B1-deep-unsupervised-learning-using-nonequilibrium-thermodynamics/</link>
        <pubDate>Fri, 01 Nov 2024 22:18:33 +0800</pubDate>
        
        <guid>https://JING.github.io/p/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B1-deep-unsupervised-learning-using-nonequilibrium-thermodynamics/</guid>
        <description>&lt;img src="https://JING.github.io/p/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B1-deep-unsupervised-learning-using-nonequilibrium-thermodynamics/cover.jpg" alt="Featured image of post 扩散模型1 | Deep Unsupervised Learning using Nonequilibrium Thermodynamics" /&gt;&lt;img src=&#34;authors.jpg&#34; style=&#34;zoom:52%&#34; /&gt;
&lt;p&gt;论文：https://arxiv.org/abs/1503.03585&lt;/p&gt;
&lt;h2 id=&#34;unified-structure-generation-for-universal-information-extraction&#34;&gt;Unified Structure Generation for Universal Information Extraction
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>通用信息抽取1 | Unified Structure Generation for Universal Information Extraction</title>
        <link>https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%961-unified-structure-generation-for-universal-information-extraction/</link>
        <pubDate>Wed, 30 Oct 2024 16:37:14 +0800</pubDate>
        
        <guid>https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%961-unified-structure-generation-for-universal-information-extraction/</guid>
        <description>&lt;img src="https://JING.github.io/p/%E9%80%9A%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%961-unified-structure-generation-for-universal-information-extraction/uie_framwork.jpg" alt="Featured image of post 通用信息抽取1 | Unified Structure Generation for Universal Information Extraction" /&gt;&lt;img src=&#34;authors.jpg&#34; style=&#34;zoom:43%&#34; /&gt;
&lt;p&gt;论文：https://arxiv.org/abs/2203.12277&lt;br&gt;
代码：https://github.com/universal-ie/UIE&lt;br&gt;
Accepted to the main conference of ACL2022&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;什么是信息抽取？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们首先简单介绍一下信息抽取，有了解的可以直接跳过。&lt;br&gt;
信息抽取(Information Extraction, IE)是自然语言处理(NLP)领域的一个任务，旨在从非结构化的文本数据中自动识别并提取结构化的信息，例如提取文本中的关键实体、关系或事件等。主要关注三个任务：&lt;br&gt;
例：Steve became CEO of Apple in 1997.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;命名实体识别(Named Entity Recognition, NER)&lt;br&gt;
NER任务的目标是识别文本中的实体(如人名、地点、组织等)并分类。对于上面给出的例句，识别实体&amp;quot;Steve&amp;quot;，类型标注为&amp;quot;person&amp;quot;；识别实体&amp;quot;Apple&amp;quot;，类型标注为&amp;quot;organization&amp;quot;；识别实体&amp;quot;1997&amp;quot;，类型标注为&amp;quot;time&amp;quot;。&lt;/li&gt;
&lt;li&gt;关系抽取(Relation Extraction)&lt;br&gt;
RE任务的目标是识别文本中的实体关系，明确它们之间的联系。对于上面给出的例句，头实体&amp;quot;Steve&amp;quot;，尾实体&amp;quot;Apple&amp;quot;，他们之间的关系为&amp;quot;work-for&amp;quot;。&lt;/li&gt;
&lt;li&gt;事件抽取(Event Extraction)&lt;br&gt;
EE任务的目标是识别文本中发生的事件，并提取出事件的参与实体、时间、地点等信息(事件参数)。对于上面给出的例句，识别触发词&amp;quot;became&amp;quot;，类型标注为&amp;quot;start-position&amp;quot;。事件下对应的三个论元&amp;quot;Steve&amp;quot;，&amp;ldquo;Apple&amp;rdquo;，&amp;ldquo;1997&amp;quot;分别扮演&amp;quot;employee&amp;rdquo;，&amp;ldquo;employer&amp;rdquo;，&amp;ldquo;time&amp;quot;的事件角色。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可以看出，对于不同的IE任务，随着任务目标的变化，需要抽取出的信息的结构也各有不同，例如在NER中要抽取出的是句子中的单词或短语，在RE任务中又需要判断两个实体间的关系。&lt;br&gt;
因此要完成不同的任务，就需要定义不同的抽取模式(即信息抽取时需要遵循的结构化规则或框架)。&lt;br&gt;
但可以观察到，这几个任务之间其实是有共通之处的，比如RE，就可以看作是NER任务的进一步扩展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是否有办法对这三个任务进行统一建模？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面我们来看一下UIE这篇文章。&lt;/p&gt;
&lt;h2 id=&#34;unified-structure-generation-for-universal-information-extraction&#34;&gt;Unified Structure Generation for Universal Information Extraction
&lt;/h2&gt;&lt;p&gt;IE受到其不同目标、异构结构和特定需求模式的影响，此前大多数IE方法都是为不同的任务设计不同的模型，这存在几个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为大量的IE任务/设置/场景开发专用架构非常复杂(比如单独设计一个模型，专门处理RE任务；单独设计一个模型，专门处理EE任务，听起来就很麻烦)。&lt;/li&gt;
&lt;li&gt;学习孤立的模型严重限制了相关任务和设置之间的知识共享(比如RE任务，NER任务中实体已经抽取好了、类别也标注好了，为什么不能直接用呢)。&lt;/li&gt;
&lt;li&gt;构建专门用于不同IE任务的数据集和知识源既昂贵又耗时(不同任务的数据集的知识是不是可以共享呢)。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;作者认为，所有IE任务都可以建模为文本到结构(text-to-structure)的转换。&lt;/p&gt;
&lt;h3 id=&#34;structured-extraction-language-for-uniform-structure-encoding-sel&#34;&gt;Structured Extraction Language for Uniform Structure Encoding (SEL)
&lt;/h3&gt;&lt;p&gt;首先，要将不同的IE结构编码成统一的表示，这样就可以在同一个文本-结构的生成框架中对各种IE任务进行统一建模。具体而言，作者将这一转换过程拆分为了两个子操作：&lt;br&gt;
例：Steve works for Apple.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定位(Spotting)：在文本中找到特定语义类型的span，将文本中的特定span根据预先定义的语义类型进行标注。例：&amp;ldquo;Steve&amp;quot;被标注为&amp;quot;Person&amp;rdquo;。&lt;/li&gt;
&lt;li&gt;关联(Associating)：对已经定位的span进行关联(例如标记实体对之间的关系)。例：将&amp;quot;Steve&amp;quot;标记为Arg1，&amp;ldquo;Apple&amp;quot;标记为Arg2(类似将&amp;quot;Steve&amp;quot;视为头实体，&amp;ldquo;Apple&amp;quot;视为尾实体)。关联Arg1和Arg2，即判断这两个实体之间的关系，我们将关系标注为&amp;quot;Work-for&amp;rdquo;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;作者使用Spot Name和Asso Name分别表示Spotting和Associating操作。Info Span则表示Spot Name和Asso Name所标记的实际文本信息。&lt;br&gt;
我们来看作者给出的一个具体示例。&lt;br&gt;
&lt;img src=&#34;SEL_example.jpg&#34; style=&#34;zoom:45%&#34; /&gt;&lt;br&gt;
例：对于文本输入&amp;quot;Steve became CEO of Apple in 1997.&amp;quot;，通过SEL生成的结构：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;RE(蓝色)：头实体&amp;quot;Steve&amp;rdquo;(Info Span)，类型标注为&amp;quot;person&amp;rdquo;(Spot Name)；尾实体&amp;quot;Apple&amp;quot; (Info Span)，类型标注为&amp;quot;organization&amp;quot;(Spot Name)；关系&amp;quot;work-for&amp;quot;(Asso Name)。&lt;/li&gt;
&lt;li&gt;EE(红色)：触发词&amp;quot;became&amp;quot;(Info Span)，类型标注为&amp;quot;start-position&amp;quot;(Spot Name)。事件下对应的三个论元&amp;quot;Steve&amp;quot; (Info Span)，&amp;ldquo;Apple&amp;rdquo; (Info Span)，&amp;ldquo;1997&amp;rdquo; (Info Span)分别扮演&amp;quot;employee&amp;quot;(Spot Name)，&amp;ldquo;employer&amp;rdquo;(Spot Name)，&amp;ldquo;time&amp;rdquo;(Spot Name)的事件角色。&lt;/li&gt;
&lt;li&gt;NER(黑色)：实体&amp;quot;Steve&amp;quot;(Info Span)，类型标注为&amp;quot;person&amp;quot;(Spot Name)；实体&amp;quot;Apple&amp;quot; (Info Span)，类型标注为&amp;quot;organization&amp;quot;(Spot Name)；实体&amp;quot;1997&amp;quot; (Info Span)，类型标注为&amp;quot;time&amp;quot;(Spot Name)。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样一来，无论对二元关系，还是N元论元结构，都可以用SEL语法表示。&lt;/p&gt;
&lt;h3 id=&#34;structural-schema-instructor-for-controllable-ie-structure-generation-ssi&#34;&gt;Structural Schema Instructor for Controllable IE Structure Generation (SSI)
&lt;/h3&gt;&lt;p&gt;虽然三个IE任务都可以通过SEL统一表示结构，但模型还不知道什么时候该做什么。&lt;br&gt;
作者设计了特殊符号[spot], [asso]和[text]，分别添加到每个Spot Name、Asso Name和输入文本序列之前，来提示模型要提取哪些信息。&lt;br&gt;
&lt;img src=&#34;uie_framwork.jpg&#34; style=&#34;zoom:42%&#34; /&gt;&lt;br&gt;
具体的例子如图所示，类似于给一个表格让模型去填写表格内容。&lt;br&gt;
但当需要提取出的信息较多、句子结构比较复杂的情况下，输入序列会变得非常长：&lt;br&gt;
&lt;img src=&#34;example.jpg&#34; style=&#34;zoom:37%&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;structure-generation-with-uie&#34;&gt;Structure Generation with UIE
&lt;/h3&gt;&lt;p&gt;简单来说，UIE的输入是SSI+Text的形式，输出是用SEL语法表示的结构。UIE整体可以看作是Encoder-Decoder架构的模型：&lt;/p&gt;
&lt;h4 id=&#34;encoder&#34;&gt;Encoder
&lt;/h4&gt;&lt;p&gt;通过Transformer Encoder对SSI $s$和文本序列$x$进行编码，生成hidden representation:
&lt;/p&gt;
$$
H = Encoder(s_1, s_2, s_{|s|}, x_1, ..., x_{|x|})
$$&lt;h4 id=&#34;decoder&#34;&gt;Decoder
&lt;/h4&gt;&lt;p&gt;使用Transformer Decoder以自回归的方式逐步生成目标SEL序列：
&lt;/p&gt;
$$
y_i, h_i^d = Decoder([H; h_1^d, ..., h_{i-1}^d])
$$&lt;p&gt;
当解码器生成特殊的结束符号&amp;lt;eos&amp;gt;时，解码过程完成。&lt;/p&gt;
&lt;p&gt;作者认为，文本-结构的生成范式将标签视为自然语言标记，这一方法可以有效地转移来自BART、T5等预训练语言模型的知识，相关任务可以很容易地共享知识，因为它们的标签具有相似的语义(例如，location和place)，并共享共同的标签-文本关联(例如，不同事件类型的受害者)。&lt;/p&gt;
&lt;h3 id=&#34;pre-training-for-uie&#34;&gt;Pre-training for UIE
&lt;/h3&gt;&lt;h4 id=&#34;预训练数据集&#34;&gt;预训练数据集
&lt;/h4&gt;&lt;p&gt;包括结构化(例如，知识库)、非结构化(例如，原始文本)和并行(例如，维基百科-维基数据链接)数据：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$D_{record}$(结构)：$D_{record}$是一个结构数据集，每个实例是一个结构化记录$y$。该数据集从ConceptNet(一个常识知识库)和Wikidata中收集结构化记录。$D_{record}$用于预训练UIE的结构解码能力，帮助模型在理解结构化记录后，能够从这些记录生成有效的输出。&lt;/li&gt;
&lt;li&gt;$D_{text}$(文本)：$D_{text}$是一个非结构化文本数据集，包含英语维基百科中的所有纯文本。$D_{text}$用于预训练UIE的语义编码能力。通过对大规模的非结构化文本进行训练，模型能够更好地理解自然语言的语义、上下文和结构特征。&lt;/li&gt;
&lt;li&gt;$D_{pair}$(文本+结构)：$D_{pair}$是文本-结构的并行数据集，每个实例由一对$(token序列x，结构化记录y)$组成。Dpair用于预训练UIE的文本到结构转换能力，使模型能够理解和处理文本与其对应结构之间的关系。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;预训练任务&#34;&gt;预训练任务
&lt;/h4&gt;&lt;p&gt;使用三个序列生成任务来预训练UIE：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Text-to-Structure Pre-training using $D_pair$：$p(y|x,s_meta)$表示在给定文本和模式的条件下生成结构记录$y$的概率。
$$
{L}_{\text {Pair}}=\sum_{(x, y) \in \mathcal{D}_{\text {pair}}}-\log p\left(y \mid x, s_{\text {meta}} ; \theta_{e}, \theta_{d}\right)
$$&lt;/li&gt;
&lt;li&gt;Structure Generation Pre-training with $D_record$：在给定之前生成的token的情况下，预测当前token $y_i$的负对数似然。
$$
{L}_{\text {Record}}=\sum_{y \in \mathcal{D}_{\text {record}}}-\log p\left(y_i \mid y_{&amp;lt i}; \theta_{d}\right)
$$&lt;/li&gt;
&lt;li&gt;Retrofitting Semantic Representation using $D_text$：给定被Mask的源文本，让模型还原被Mask的部分。
$$
{L}_{\text {Text}}=\sum_{x \in \mathcal{D}_{\text {text}}}-\log p\left(x^{\prime \prime} \mid x^{\prime} ; \theta_{e}, \theta_{d}\right)
$$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终目标是将上述任务结合起来：
&lt;/p&gt;
$$
{L}={L}_{\text {Pair}} + {L}_{\text {Record}} + {L}_{\text {Text}}
$$&lt;h3 id=&#34;fine-tuning-for-uie&#34;&gt;Fine-tuning for UIE
&lt;/h3&gt;&lt;p&gt;给定一个标记语料库$D_task={(s, x, y)}$，使用teacher-forcing cross-entropy loss来微调UIE模型：
&lt;/p&gt;
$$
{L}_{FT}=\sum_{(s, x, y) \in \mathcal{D}_{\text {Task}}}-\log p\left(y \mid x, s; \theta_{e}, \theta_{d}\right)
$$&lt;p&gt;
为了缓解暴露偏差，在解码过程中，作者还设计了一种拒绝机制。给定实例$(s, x, y)$，使用SEL对$y$进行编码，随机加入$[NULL]$噪声。具体示例如图所示：&lt;br&gt;
&lt;img src=&#34;noise_example.jpg&#34; style=&#34;zoom:45%&#34; /&gt;&lt;br&gt;
句子中没有facility实体，在模型学习时随机注入&amp;quot;(facility：[NULL])&amp;ldquo;的噪声。通过这种方式，UIE可以通过生成[NULL]来有效地学习拒绝误导生成。&lt;/p&gt;
&lt;h2 id=&#34;experiment&#34;&gt;Experiment
&lt;/h2&gt;&lt;img src=&#34;main_result.jpg&#34; style=&#34;zoom:58%&#34; /&gt;   
&lt;p&gt;可以看到，UIE在多个任务上SOTA。&lt;br&gt;
ps：其他的实验结果具体可以看原文，在这里就不详细说明了。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;提出了一个统一的文本到结构生成框架——UIE(T5+结构化生成)，它可以通用地建模不同的IE任务，自适应地生成有针对性的结构，并从不同的知识源中学习通用的IE能力：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多样化的目标结构 &amp;mdash;&amp;gt; SEL统一编码异构抽取结构&lt;/li&gt;
&lt;li&gt;需求特定的抽取模式 &amp;mdash;&amp;gt; 基于模式的提示机制SSI&lt;/li&gt;
&lt;li&gt;不同任务之间知识难以共享 &amp;mdash;&amp;gt; 在包含多个任务的数据集上预训练模型&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>归档</title>
        <link>https://JING.github.io/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>https://JING.github.io/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>关于</title>
        <link>https://JING.github.io/%E5%85%B3%E4%BA%8E/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://JING.github.io/%E5%85%B3%E4%BA%8E/</guid>
        <description>&lt;p&gt;This is a test page for i18n support.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>链接</title>
        <link>https://JING.github.io/%E9%93%BE%E6%8E%A5/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://JING.github.io/%E9%93%BE%E6%8E%A5/</guid>
        <description>&lt;p&gt;To use this feature, add &lt;code&gt;links&lt;/code&gt; section to frontmatter.&lt;/p&gt;
&lt;p&gt;This page&amp;rsquo;s frontmatter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;links&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub is the world&amp;#39;s largest software development platform.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://www.typescriptlang.org&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ts-logo-128.jpg&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;image&lt;/code&gt; field accepts both local and external images.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>搜索</title>
        <link>https://JING.github.io/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://JING.github.io/search/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
